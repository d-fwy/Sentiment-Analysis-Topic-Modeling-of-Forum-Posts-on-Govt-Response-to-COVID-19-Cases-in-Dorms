{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Prediction Modeling\n",
    "\n",
    "### Using Supervised Learning classification models, Logistic Regression and Multinomial Naive Bayes models, to label posts in test set\n",
    "\n",
    "Having gathered the posts by scraping, a sample of 1000 posts were labelled manually so as to train models to subsequently predict labels on the remainder of the dataset (around 9000 posts). *Textblob and VADER (unsupervised learning text classification models) were initially used to predict the sentiment of the posts, but the results were not accurate*\n",
    "\n",
    "The labels are: \n",
    "- **0 for negative sentiment** \n",
    "- **1 for neutral sentiment**\n",
    "- **2 for positive sentiment**\n",
    "\n",
    "It should be noted that the labels were highly skewed, with around 80% of the posts classed as neutral, 15% as negative and 5% positive. This affected how well the model was able to predict the sentiment of unlabelled posts. \n",
    "\n",
    "The models chosen were classification models - Logistic Regression and Multinomial Naive Bayes, Long Short Term Memory Recurrent Neural Net model and BERT. \n",
    "\n",
    "It was found that the Multinomial Naive Bayes model was the most accurate in predicting sentiment. It had high Accuracy, ROC AUC and F1 scores, with little variance between the train and validation sets, as well as being more likely to assign minority classes, compared to the Logistic Regression Model. The performance of LSTM RNN and BERT models paled in comparison as well. For BERT, it could be that the pretrained model did not generalise well on the dataset, due to the nature of the local Singlish language (in terms of different words and sentence structures). The LSTM RNN model also did not do well, as it relied on learning words before and after a significant word, instead of standalone words, which did not work particularly well for this dataset.  \n",
    "\n",
    "It should be noted that SMOTE was used to try to address the issue of unbalanced classes in the data, all of which did not perform as well as a model where the minority classes were not oversampled in the model. \n",
    "\n",
    "The process of assessing a production model for sentiment analysis is as follows:\n",
    "1. **Train Multinomial NB model on all posts in train set, which have labelled sentiments (THIS NOTEBOOK)** \n",
    "2. **Predict label on posts in test set (THIS NOTEBOOK)** \n",
    "3. Check accuracy of predictions and make changes to incorrect labels \n",
    "4. Collate labelled posts in train and test sets to train final production model \n",
    "\n",
    "While I acknowledge that it is not ideal to use a regular supervised learning classification models to predict the sentiment of text posts, this was the best method for this particular dataset. I believe that with more data gathered, a LSTM RNN or BERT model can be sufficiently trained to better predict sentiment of posts from Singaporean forums.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Importing libraries and collating labelled posts in train set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>post</th>\n",
       "      <th>label</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>post_clean_for_rnn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>There is no new cluster beside the dorm for tw...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-10-04 08:34:00</td>\n",
       "      <td>hardwarezone</td>\n",
       "      <td>there is no new cluster beside the dorm for tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>&gt;For consistency and accuracy, it could be eas...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-11 12:26:38</td>\n",
       "      <td>reddit</td>\n",
       "      <td>for consistency and accuracy it could be easie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Only IQ lower than 86 will believe this CSB.Wh...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-23 10:42:00</td>\n",
       "      <td>hardwarezone</td>\n",
       "      <td>only iq lower than 86 will believe this csb wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I work nearby to the Westlite and Toh Guan Dor...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-06 20:55:47</td>\n",
       "      <td>reddit</td>\n",
       "      <td>i work nearby to the westlite and toh guan dor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Ho seh liao</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-09-04 21:43:00</td>\n",
       "      <td>hardwarezone</td>\n",
       "      <td>ho seh liao</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               post  label  \\\n",
       "0           0  There is no new cluster beside the dorm for tw...    2.0   \n",
       "1           1  >For consistency and accuracy, it could be eas...    0.0   \n",
       "2           2  Only IQ lower than 86 will believe this CSB.Wh...    0.0   \n",
       "3           3  I work nearby to the Westlite and Toh Guan Dor...    0.0   \n",
       "4           4                                        Ho seh liao    0.0   \n",
       "\n",
       "                  date        source  \\\n",
       "0  2020-10-04 08:34:00  hardwarezone   \n",
       "1  2020-04-11 12:26:38        reddit   \n",
       "2  2020-04-23 10:42:00  hardwarezone   \n",
       "3  2020-04-06 20:55:47        reddit   \n",
       "4  2020-09-04 21:43:00  hardwarezone   \n",
       "\n",
       "                                  post_clean_for_rnn  \n",
       "0  there is no new cluster beside the dorm for tw...  \n",
       "1  for consistency and accuracy it could be easie...  \n",
       "2  only iq lower than 86 will believe this csb wh...  \n",
       "3  i work nearby to the westlite and toh guan dor...  \n",
       "4                                        ho seh liao  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./labelled_posts/train_labelled_clean.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8213, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns = ['Unnamed: 0'], inplace=True)\n",
    "train.fillna('nopost', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Preprocessing of posts in train data for modeling \n",
    "\n",
    "- Tokenising\n",
    "- Removing stopwords\n",
    "- Lemmatising\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preprocess train['post']\n",
    "\n",
    "#dealing with stopwords \n",
    "\n",
    "#first cut - removing words from stopwords that indicate sentiment \n",
    "remove_words = [\"no\", \"not\", \"against\", \"don't\", \"should\", \"should've\", \"couldn\", \"couldn't\",'didn', \"didn't\",\n",
    "                   'doesn',\"doesn't\",'shouldn',\"shouldn't\",'wasn',\"wasn't\",'weren',\"weren't\",'won',\"won't\",\n",
    "                   'wouldn',\"wouldn't\"]\n",
    "stopwords = [word for word in stopwords.words('english') if word not in remove_words]\n",
    "print(len(stopwords))\n",
    "\n",
    "#also adding words that are either common words, singaporean slang or noisy words from forum posts\n",
    "add_words = ['foreign', 'migrant', 'worker', 'workers', 'fw', 'dorm', 'dorms', 'dormitory', 'dormitories', 'covid', \n",
    "             '19', 'cases', 'virus', 'coronavirus', 'gagt', 'ah', 'liao', 'lah', 'trt', 'huawei', 'samsung',\n",
    "            'xiaomi', 'l21a', '32']\n",
    "stopwords.extend(add_words)\n",
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(word):\n",
    "     \n",
    "    # tokenize and convert lower \n",
    "    # \\w also removes punctuation - may need to add extra no punc if tokenizing does not do it\n",
    "    token = RegexpTokenizer(r'\\w+')\n",
    "    tokens = token.tokenize(word.lower())\n",
    "    \n",
    "   #remove stopwords \n",
    "    no_stop = [word for word in tokens if word not in stopwords]\n",
    "\n",
    "    no_stopword = (' '.join(no_stop))\n",
    "        \n",
    "    #lemmatize words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lem = [lemmatizer.lemmatize(word) for word in no_stopword]\n",
    "    \n",
    "    #return words as a single string \n",
    "    return(''.join(lem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking post_clean: \n",
      "['no new cluster beside two days', 'consistency accuracy could easier use data new moh situation report separates non foreigners citizen pr think count named clusters either linked construction sites live non cluster get categorized linked clusters pending investigations respectively moh situation report 28 3 10 4 ltp holders 545 linked clusters 126 linked clusters 141 pending investigations whereas estimate time period 702 construction related reason make graphs really 2 separate problems singapore circuit breaker slow growth general public stopping work construction sites circuit breaker doesn help construction site problem construction site problem tackled improving living conditions testing separating sick well conversely issues way many people exercising eating hawker centres sneakily meeting etc affect non problem yes testing situation worrisome not know prioritizing tests would political suicide moh admit either prioritizing sc pr first patriotism urgent separate sick cramped conditions', 'iq lower 86 believe csb maids pregnant nothing fws sex friends catholic believe immaculate inception like mary', 'work nearby westlite toh guan initial reports westlite saw still open operating usual even food stalls provision shop rather surprised didn try isolate situation earlier understand maybe couldn put everyone shn immediately financial implications wonder still allowed still congregate eating place also allowed provision shop stay open didn see sanitizing stuff going fair telecommuting week may done without seeing many decided lock place also spread toh guan across road couple units quite frustrated something wasn done earlier', 'ho seh']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>label</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>post_clean_for_rnn</th>\n",
       "      <th>post_clean_nb_logreg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There is no new cluster beside the dorm for tw...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-10-04 08:34:00</td>\n",
       "      <td>hardwarezone</td>\n",
       "      <td>there is no new cluster beside the dorm for tw...</td>\n",
       "      <td>no new cluster beside two days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;For consistency and accuracy, it could be eas...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-11 12:26:38</td>\n",
       "      <td>reddit</td>\n",
       "      <td>for consistency and accuracy it could be easie...</td>\n",
       "      <td>consistency accuracy could easier use data new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Only IQ lower than 86 will believe this CSB.Wh...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-23 10:42:00</td>\n",
       "      <td>hardwarezone</td>\n",
       "      <td>only iq lower than 86 will believe this csb wh...</td>\n",
       "      <td>iq lower 86 believe csb maids pregnant nothing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I work nearby to the Westlite and Toh Guan Dor...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-06 20:55:47</td>\n",
       "      <td>reddit</td>\n",
       "      <td>i work nearby to the westlite and toh guan dor...</td>\n",
       "      <td>work nearby westlite toh guan initial reports ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ho seh liao</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-09-04 21:43:00</td>\n",
       "      <td>hardwarezone</td>\n",
       "      <td>ho seh liao</td>\n",
       "      <td>ho seh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I’m not saying we caused this spread among the...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-16 23:59:35</td>\n",
       "      <td>reddit</td>\n",
       "      <td>i m not saying we caused this spread among the...</td>\n",
       "      <td>not saying caused spread among agree oversight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1. From healthy no wear mask to Mask mandatory...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-14 20:29:00</td>\n",
       "      <td>hardwarezone</td>\n",
       "      <td>1 from healthy no wear mask to mask mandatory ...</td>\n",
       "      <td>1 healthy no wear mask mask mandatory 2 many 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Exactly. People don’t even wanna let our publi...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-05-27 20:28:30</td>\n",
       "      <td>reddit</td>\n",
       "      <td>exactly people don t even wanna let our public...</td>\n",
       "      <td>exactly people even wanna let public servants ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The current situation is beyond this woman. 24...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-06-06 14:40:00</td>\n",
       "      <td>sgtalk</td>\n",
       "      <td>the current situation is beyond this woman 24h...</td>\n",
       "      <td>current situation beyond woman 24hrs day not e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Iran, followed by China, India, Israel, Saudi ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-23 17:52:00</td>\n",
       "      <td>hardwarezone</td>\n",
       "      <td>iran followed by china india israel saudi arab...</td>\n",
       "      <td>iran followed china india israel saudi arabia ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                post  label  \\\n",
       "0  There is no new cluster beside the dorm for tw...    2.0   \n",
       "1  >For consistency and accuracy, it could be eas...    0.0   \n",
       "2  Only IQ lower than 86 will believe this CSB.Wh...    0.0   \n",
       "3  I work nearby to the Westlite and Toh Guan Dor...    0.0   \n",
       "4                                        Ho seh liao    0.0   \n",
       "5  I’m not saying we caused this spread among the...    0.0   \n",
       "6  1. From healthy no wear mask to Mask mandatory...    0.0   \n",
       "7  Exactly. People don’t even wanna let our publi...    2.0   \n",
       "8  The current situation is beyond this woman. 24...    1.0   \n",
       "9  Iran, followed by China, India, Israel, Saudi ...    0.0   \n",
       "\n",
       "                  date        source  \\\n",
       "0  2020-10-04 08:34:00  hardwarezone   \n",
       "1  2020-04-11 12:26:38        reddit   \n",
       "2  2020-04-23 10:42:00  hardwarezone   \n",
       "3  2020-04-06 20:55:47        reddit   \n",
       "4  2020-09-04 21:43:00  hardwarezone   \n",
       "5  2020-04-16 23:59:35        reddit   \n",
       "6  2020-04-14 20:29:00  hardwarezone   \n",
       "7  2020-05-27 20:28:30        reddit   \n",
       "8  2020-06-06 14:40:00        sgtalk   \n",
       "9  2020-04-23 17:52:00  hardwarezone   \n",
       "\n",
       "                                  post_clean_for_rnn  \\\n",
       "0  there is no new cluster beside the dorm for tw...   \n",
       "1  for consistency and accuracy it could be easie...   \n",
       "2  only iq lower than 86 will believe this csb wh...   \n",
       "3  i work nearby to the westlite and toh guan dor...   \n",
       "4                                        ho seh liao   \n",
       "5  i m not saying we caused this spread among the...   \n",
       "6  1 from healthy no wear mask to mask mandatory ...   \n",
       "7  exactly people don t even wanna let our public...   \n",
       "8  the current situation is beyond this woman 24h...   \n",
       "9  iran followed by china india israel saudi arab...   \n",
       "\n",
       "                                post_clean_nb_logreg  \n",
       "0                     no new cluster beside two days  \n",
       "1  consistency accuracy could easier use data new...  \n",
       "2  iq lower 86 believe csb maids pregnant nothing...  \n",
       "3  work nearby westlite toh guan initial reports ...  \n",
       "4                                             ho seh  \n",
       "5  not saying caused spread among agree oversight...  \n",
       "6  1 healthy no wear mask mask mandatory 2 many 9...  \n",
       "7  exactly people even wanna let public servants ...  \n",
       "8  current situation beyond woman 24hrs day not e...  \n",
       "9  iran followed china india israel saudi arabia ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_clean = []\n",
    "\n",
    "for p in train[\"post\"]:\n",
    "    post_clean.append(preprocess(p))\n",
    "\n",
    "print(f\"checking post_clean: \\n{post_clean[0:5]}\")\n",
    "\n",
    "train['post_clean_nb_logreg'] = post_clean\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Preparing data for modeling\n",
    "\n",
    "As stated earlier, I had tried oversampling the minority classes (0 and 2) with SMOTE. All of these methods did not perform as well as the model without oversampling. \n",
    "- Models with smote had lower accuracy, ROC AUC and f1-scores than models without SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features matrix\n",
    "\n",
    "X = train['post_clean_nb_logreg']\n",
    "y = train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    0.857421\n",
       "0.0    0.116888\n",
       "2.0    0.025691\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baseline \n",
    "y.value_counts(normalize=True)\n",
    "\n",
    "# 0 - negative post\n",
    "# 1 - neutral post \n",
    "# 2 - positive post "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test-split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    stratify=y, \n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Logistic Regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logreg model with no SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   45.6s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1350 out of 1350 | elapsed:  5.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('lr',\n",
       "                                        LogisticRegression(solver='liblinear'))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [0.2, 0.3, 0.7],\n",
       "                         'cvec__max_features': [100, 200, 500],\n",
       "                         'cvec__min_df': [2, 4, 6],\n",
       "                         'cvec__ngram_range': [(1, 1)],\n",
       "                         'lr__C': array([1.00000000e-05, 4.64158883e-05, 2.15443469e-04, 1.00000000e-03,\n",
       "       4.64158883e-03, 2.15443469e-02, 1.00000000e-01, 4.64158883e-01,\n",
       "       2.15443469e+00, 1.00000000e+01]),\n",
       "                         'lr__penalty': ['l1']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logreg\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('lr', LogisticRegression(solver = 'liblinear'))\n",
    "])\n",
    "\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [100, 200, 500],\n",
    "    'cvec__min_df': [2, 4, 6],\n",
    "    'cvec__max_df': [0.2, 0.3, 0.7],\n",
    "    'cvec__ngram_range': [(1,1)],\n",
    "    'lr__penalty': ['l1'],\n",
    "    'lr__C': np.logspace(-5, 1, 10)\n",
    "}\n",
    "\n",
    "gscv_lr = GridSearchCV(pipe, pipe_params, cv=5, n_jobs =-1, verbose=1)\n",
    "gscv_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.3,\n",
       " 'cvec__max_features': 500,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'lr__C': 0.46415888336127725,\n",
       " 'lr__penalty': 'l1'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec',\n",
       "                 CountVectorizer(max_df=0.3, max_features=500, min_df=2)),\n",
       "                ('lr',\n",
       "                 LogisticRegression(C=0.46415888336127725, penalty='l1',\n",
       "                                    solver='liblinear'))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting model with optimised params \n",
    "opt_gscv_lr = gscv_lr.best_estimator_\n",
    "opt_gscv_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>optimised_params</th>\n",
       "      <th>train_acc_score</th>\n",
       "      <th>test_acc_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>train_f1_score</th>\n",
       "      <th>test_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cvec + logistic regression</td>\n",
       "      <td>{'cvec__max_df': 0.3, 'cvec__max_features': 50...</td>\n",
       "      <td>0.884779</td>\n",
       "      <td>0.863664</td>\n",
       "      <td>0.714364</td>\n",
       "      <td>0.909458</td>\n",
       "      <td>0.895506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model  \\\n",
       "0  cvec + logistic regression   \n",
       "\n",
       "                                    optimised_params  train_acc_score  \\\n",
       "0  {'cvec__max_df': 0.3, 'cvec__max_features': 50...         0.884779   \n",
       "\n",
       "   test_acc_score  roc_auc_score  train_f1_score  test_f1_score  \n",
       "0        0.863664       0.714364        0.909458       0.895506  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred 0</th>\n",
       "      <th>pred 1</th>\n",
       "      <th>pred 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual 0</th>\n",
       "      <td>39</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual 1</th>\n",
       "      <td>26</td>\n",
       "      <td>1378</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual 2</th>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pred 0  pred 1  pred 2\n",
       "actual 0      39     152       1\n",
       "actual 1      26    1378       5\n",
       "actual 2       7      33       2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.542     0.203     0.295       192\n",
      "         1.0      0.882     0.978     0.927      1409\n",
      "         2.0      0.250     0.048     0.080        42\n",
      "\n",
      "    accuracy                          0.864      1643\n",
      "   macro avg      0.558     0.410     0.434      1643\n",
      "weighted avg      0.826     0.864     0.832      1643\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create dataframe of metrics based on optimised model \n",
    "opt_results_lr = pd.DataFrame()\n",
    "\n",
    "opt_results_lr['model'] = ['cvec + logistic regression']\n",
    "opt_results_lr['optimised_params'] = [gscv_lr.best_params_]\n",
    "opt_results_lr['train_acc_score'] = opt_gscv_lr.score(X_train, y_train)\n",
    "opt_results_lr['test_acc_score'] = opt_gscv_lr.score(X_test, y_test)\n",
    "\n",
    "pred_proba = opt_gscv_lr.predict_proba(X_test)\n",
    "opt_results_lr['roc_auc_score'] = roc_auc_score(y_test, pred_proba, multi_class=\"ovo\", average = 'weighted')\n",
    "opt_results_lr['train_f1_score'] = f1_score((opt_gscv_lr.predict(X_train)), y_train, average = 'weighted')\n",
    "opt_results_lr['test_f1_score'] = f1_score((opt_gscv_lr.predict(X_test)), y_test, average = 'weighted')\n",
    "\n",
    "display(opt_results_lr)\n",
    "\n",
    "#confusion matrix for logreg\n",
    "\n",
    "y_pred_lr = opt_gscv_lr.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_lr)\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     index = ['actual 0','actual 1','actual 2'], \n",
    "                     columns = ['pred 0','pred 1','pred 2'])\n",
    "display(cm_df)\n",
    "\n",
    "print(classification_report(y_test, y_pred_lr, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logreg model with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.46415888336127725, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing logreg model with SMOTE for unbalanced classes - did not perform well!!!\n",
    "\n",
    "#cvec\n",
    "cvec = CountVectorizer(max_df=0.2, max_features=500, min_df=6)\n",
    "X_train = cvec.fit_transform(X_train).toarray()\n",
    "X_test = cvec.transform(X_test).toarray()\n",
    "\n",
    "#SMOTE for inbalanced classes \n",
    "sm = SMOTE()\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "#fit model \n",
    "lr = LogisticRegression(C=0.46415888336127725, penalty='l1', solver='liblinear')\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of cvec + smote + logreg model on train data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_acc_score</th>\n",
       "      <th>test_acc_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>train_f1_score</th>\n",
       "      <th>test_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cvec + smote + logreg</td>\n",
       "      <td>0.692112</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.570307</td>\n",
       "      <td>0.69884</td>\n",
       "      <td>0.502009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model  train_acc_score  test_acc_score  roc_auc_score  \\\n",
       "0  cvec + smote + logreg         0.692112        0.580645       0.570307   \n",
       "\n",
       "   train_f1_score  test_f1_score  \n",
       "0         0.69884       0.502009  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred 0</th>\n",
       "      <th>pred 1</th>\n",
       "      <th>pred 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual 0</th>\n",
       "      <td>94</td>\n",
       "      <td>72</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual 1</th>\n",
       "      <td>270</td>\n",
       "      <td>851</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual 2</th>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pred 0  pred 1  pred 2\n",
       "actual 0      94      72      26\n",
       "actual 1     270     851     288\n",
       "actual 2       7      26       9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.253     0.490     0.334       192\n",
      "         1.0      0.897     0.604     0.722      1409\n",
      "         2.0      0.028     0.214     0.049        42\n",
      "\n",
      "    accuracy                          0.581      1643\n",
      "   macro avg      0.393     0.436     0.368      1643\n",
      "weighted avg      0.799     0.581     0.659      1643\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_logreg = pd.DataFrame()\n",
    "\n",
    "model_logreg['model'] = ['cvec + smote + logreg']\n",
    "model_logreg['train_acc_score'] = lr.score(X_train, y_train)\n",
    "model_logreg['test_acc_score'] = lr.score(X_test, y_test)\n",
    "\n",
    "pred_proba = lr.predict_proba(X_test)\n",
    "model_logreg['roc_auc_score'] = roc_auc_score(y_test, pred_proba, multi_class=\"ovo\", average = 'weighted')\n",
    "model_logreg['train_f1_score'] = f1_score((lr.predict(X_train)), y_train, average = 'weighted')\n",
    "model_logreg['test_f1_score'] = f1_score((lr.predict(X_test)), y_test, average = 'weighted')\n",
    "\n",
    "print('Performance of cvec + smote + logreg model on train data')\n",
    "display(model_logreg)\n",
    "\n",
    "cm = confusion_matrix(y_test, lr.predict(X_test))\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     index = ['actual 0','actual 1','actual 2'], \n",
    "                     columns = ['pred 0','pred 1','pred 2'])\n",
    "display(cm_df)\n",
    "print(classification_report(y_test, lr.predict(X_test), digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Multinomial Naive Bayes model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial NB without SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done 135 out of 135 | elapsed:   40.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('nb', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [0.2, 0.3, 0.7],\n",
       "                         'cvec__max_features': [200, 300, 500],\n",
       "                         'cvec__min_df': [2, 4, 6],\n",
       "                         'cvec__ngram_range': [(1, 1)]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [200, 300, 500],\n",
    "    'cvec__min_df': [2, 4, 6],\n",
    "    'cvec__max_df': [0.2, 0.3, 0.7],\n",
    "    'cvec__ngram_range': [(1,1)]}\n",
    "\n",
    "\n",
    "gscv_nb = GridSearchCV(pipe, pipe_params, cv=5, n_jobs =-1, verbose=1)\n",
    "gscv_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.3,\n",
       " 'cvec__max_features': 300,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv_nb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec',\n",
       "                 CountVectorizer(max_df=0.3, max_features=300, min_df=2)),\n",
       "                ('nb', MultinomialNB())])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting model with optimised params \n",
    "opt_gscv_nb = gscv_nb.best_estimator_\n",
    "opt_gscv_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>optimised_params</th>\n",
       "      <th>train_acc_score</th>\n",
       "      <th>test_acc_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>train_f1_score</th>\n",
       "      <th>test_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tvec + multinomial nb</td>\n",
       "      <td>{'cvec__max_df': 0.3, 'cvec__max_features': 30...</td>\n",
       "      <td>0.862709</td>\n",
       "      <td>0.846622</td>\n",
       "      <td>0.697404</td>\n",
       "      <td>0.874432</td>\n",
       "      <td>0.858131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model                                   optimised_params  \\\n",
       "0  tvec + multinomial nb  {'cvec__max_df': 0.3, 'cvec__max_features': 30...   \n",
       "\n",
       "   train_acc_score  test_acc_score  roc_auc_score  train_f1_score  \\\n",
       "0         0.862709        0.846622       0.697404        0.874432   \n",
       "\n",
       "   test_f1_score  \n",
       "0       0.858131  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred 0</th>\n",
       "      <th>pred 1</th>\n",
       "      <th>pred 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual 0</th>\n",
       "      <td>63</td>\n",
       "      <td>121</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual 1</th>\n",
       "      <td>77</td>\n",
       "      <td>1322</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual 2</th>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pred 0  pred 1  pred 2\n",
       "actual 0      63     121       8\n",
       "actual 1      77    1322      10\n",
       "actual 2       7      29       6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.429     0.328     0.372       192\n",
      "         1.0      0.898     0.938     0.918      1409\n",
      "         2.0      0.250     0.143     0.182        42\n",
      "\n",
      "    accuracy                          0.847      1643\n",
      "   macro avg      0.526     0.470     0.490      1643\n",
      "weighted avg      0.827     0.847     0.835      1643\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create dataframe of metrics based on optimised model \n",
    "opt_results_nb = pd.DataFrame()\n",
    "\n",
    "opt_results_nb['model'] = ['tvec + multinomial nb']\n",
    "opt_results_nb['optimised_params'] = [gscv_nb.best_params_]\n",
    "opt_results_nb['train_acc_score'] = opt_gscv_nb.score(X_train, y_train)\n",
    "opt_results_nb['test_acc_score'] = opt_gscv_nb.score(X_test, y_test)\n",
    "\n",
    "pred_proba = opt_gscv_nb.predict_proba(X_test)\n",
    "opt_results_nb['roc_auc_score'] = roc_auc_score(y_test, pred_proba, multi_class=\"ovo\", average = 'weighted')\n",
    "opt_results_nb['train_f1_score'] = f1_score((opt_gscv_nb.predict(X_train)), y_train, average = 'weighted')\n",
    "opt_results_nb['test_f1_score'] = f1_score((opt_gscv_nb.predict(X_test)), y_test, average = 'weighted')\n",
    "\n",
    "display(opt_results_nb)\n",
    "\n",
    "#confusion matrix and classification report for multinomial nb \n",
    "\n",
    "y_pred_nb = opt_gscv_nb.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_nb)\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     index = ['actual 0','actual 1','actual 2'], \n",
    "                     columns = ['pred 0','pred 1','pred 2'])\n",
    "display(cm_df)\n",
    "print('')\n",
    "print(classification_report(y_test, y_pred_nb, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial NB with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing multinomial naive bayes model with SMOTE for unbalanced classes \n",
    "\n",
    "#cvec\n",
    "cvec = CountVectorizer(max_df=0.3, max_features=300, min_df=2)\n",
    "X_train = cvec.fit_transform(X_train).toarray()\n",
    "X_test = cvec.transform(X_test).toarray()\n",
    "\n",
    "#SMOTE for inbalanced classes \n",
    "sm = SMOTE()\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "#fit model \n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of cvec + smote + multinomial nb model on train data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_acc_score</th>\n",
       "      <th>test_acc_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>train_f1_score</th>\n",
       "      <th>test_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cvec + smote + nb</td>\n",
       "      <td>0.564294</td>\n",
       "      <td>0.549604</td>\n",
       "      <td>0.592483</td>\n",
       "      <td>0.563384</td>\n",
       "      <td>0.468342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model  train_acc_score  test_acc_score  roc_auc_score  \\\n",
       "0  cvec + smote + nb         0.564294        0.549604       0.592483   \n",
       "\n",
       "   train_f1_score  test_f1_score  \n",
       "0        0.563384       0.468342  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred 0</th>\n",
       "      <th>pred 1</th>\n",
       "      <th>pred 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual 0</th>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual 1</th>\n",
       "      <td>406</td>\n",
       "      <td>796</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual 2</th>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pred 0  pred 1  pred 2\n",
       "actual 0     100      60      32\n",
       "actual 1     406     796     207\n",
       "actual 2      12      23       7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.429     0.328     0.372       192\n",
      "         1.0      0.898     0.938     0.918      1409\n",
      "         2.0      0.250     0.143     0.182        42\n",
      "\n",
      "    accuracy                          0.847      1643\n",
      "   macro avg      0.526     0.470     0.490      1643\n",
      "weighted avg      0.827     0.847     0.835      1643\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#eval model performance \n",
    "model_nb = pd.DataFrame()\n",
    "\n",
    "model_nb['model'] = ['cvec + smote + nb']\n",
    "model_nb['train_acc_score'] = nb.score(X_train, y_train)\n",
    "model_nb['test_acc_score'] = nb.score(X_test, y_test)\n",
    "\n",
    "pred_proba = nb.predict_proba(X_test)\n",
    "model_nb['roc_auc_score'] = roc_auc_score(y_test, pred_proba, multi_class=\"ovo\", average = 'weighted')\n",
    "model_nb['train_f1_score'] = f1_score((nb.predict(X_train)), y_train, average = 'weighted')\n",
    "model_nb['test_f1_score'] = f1_score((nb.predict(X_test)), y_test, average = 'weighted')\n",
    "\n",
    "print('Performance of cvec + smote + multinomial nb model on train data')\n",
    "display(model_nb)\n",
    "\n",
    "cm = confusion_matrix(y_test, nb.predict(X_test))\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     index = ['actual 0','actual 1','actual 2'], \n",
    "                     columns = ['pred 0','pred 1','pred 2'])\n",
    "display(cm_df)\n",
    "print(classification_report(y_test, y_pred_nb, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.18869235e-02, 9.87847390e-01, 2.65686313e-04],\n",
       "       [6.38742299e-02, 7.64853133e-01, 1.71272637e-01],\n",
       "       [1.21534181e-02, 9.87004193e-01, 8.42388808e-04],\n",
       "       [3.33333333e-01, 3.33333333e-01, 3.33333333e-01],\n",
       "       [3.33333333e-01, 3.33333333e-01, 3.33333333e-01],\n",
       "       [8.14507165e-01, 1.63370896e-01, 2.21219387e-02],\n",
       "       [5.16419272e-01, 4.50330594e-01, 3.32501349e-02],\n",
       "       [5.62692199e-01, 2.88031493e-03, 4.34427486e-01],\n",
       "       [6.38847606e-01, 3.60259118e-01, 8.93275734e-04],\n",
       "       [5.70538256e-04, 9.99372809e-01, 5.66531570e-05]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_proba[50:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 2., 0., 0., 1., 1.,\n",
       "       1., 0., 2.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.predict(X_test)[50:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of cvec + smote + multinomial model on train data with threshold adjustment\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_acc_score</th>\n",
       "      <th>test_acc_score</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>train_f1_score</th>\n",
       "      <th>test_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cvec + smote + nb</td>\n",
       "      <td>0.564294</td>\n",
       "      <td>0.549604</td>\n",
       "      <td>0.592483</td>\n",
       "      <td>0.563384</td>\n",
       "      <td>0.468342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model  train_acc_score  test_acc_score  roc_auc_score  \\\n",
       "0  cvec + smote + nb         0.564294        0.549604       0.592483   \n",
       "\n",
       "   train_f1_score  test_f1_score  \n",
       "0        0.563384       0.468342  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred 0</th>\n",
       "      <th>pred 1</th>\n",
       "      <th>pred 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual 0</th>\n",
       "      <td>42</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual 1</th>\n",
       "      <td>46</td>\n",
       "      <td>1363</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual 2</th>\n",
       "      <td>6</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pred 0  pred 1  pred 2\n",
       "actual 0      42     150       0\n",
       "actual 1      46    1363       0\n",
       "actual 2       6      36       0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.447     0.219     0.294       192\n",
      "         1.0      0.880     0.967     0.922      1409\n",
      "         2.0      0.000     0.000     0.000        42\n",
      "\n",
      "    accuracy                          0.855      1643\n",
      "   macro avg      0.442     0.395     0.405      1643\n",
      "weighted avg      0.807     0.855     0.825      1643\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dorafoong/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#eval model performance WITH THRESHOLD ADJUSTMENT - no go!!!!\n",
    "\n",
    "model_nb = pd.DataFrame()\n",
    "\n",
    "model_nb['model'] = ['cvec + smote + nb']\n",
    "model_nb['train_acc_score'] = nb.score(X_train, y_train)\n",
    "model_nb['test_acc_score'] = nb.score(X_test, y_test)\n",
    "\n",
    "pred_proba = nb.predict_proba(X_test)\n",
    "model_nb['roc_auc_score'] = roc_auc_score(y_test, pred_proba, multi_class=\"ovo\", average = 'weighted')\n",
    "model_nb['train_f1_score'] = f1_score((nb.predict(X_train)), y_train, average = 'weighted')\n",
    "model_nb['test_f1_score'] = f1_score((nb.predict(X_test)), y_test, average = 'weighted')\n",
    "\n",
    "print('Performance of cvec + smote + multinomial model on train data with threshold adjustment')\n",
    "display(model_nb)\n",
    "\n",
    "\n",
    "THRESHOLD = .05\n",
    "\n",
    "preds = np.where(nb.predict_proba(X_test)[:,1] > THRESHOLD, 1, 0)\n",
    "\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     index = ['actual 0','actual 1','actual 2'], \n",
    "                     columns = ['pred 0','pred 1','pred 2'])\n",
    "display(cm_df)\n",
    "print(classification_report(y_test, preds, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Predicting sentiment of posts in test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>post_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Need more camp to house all foreign worker</td>\n",
       "      <td>2020-04-15 15:09:00</td>\n",
       "      <td>hardwarezone</td>\n",
       "      <td>need camp house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Im interested in the clusters esp new ones. Wh...</td>\n",
       "      <td>2020-04-29 23:07:00</td>\n",
       "      <td>hardwarezone</td>\n",
       "      <td>im interested clusters esp new ones see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>did the virus make his kkj buay kia?</td>\n",
       "      <td>2020-04-23 21:22:00</td>\n",
       "      <td>hardwarezone</td>\n",
       "      <td>make kkj buay kia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I’m not saying there isn’t room for improvemen...</td>\n",
       "      <td>2020-04-08 11:23:23</td>\n",
       "      <td>reddit</td>\n",
       "      <td>not saying room improvement point choice nsfs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abnn good life no need work get paid and free ...</td>\n",
       "      <td>2020-04-05 13:04:00</td>\n",
       "      <td>hardwarezone</td>\n",
       "      <td>abnn good life no need work get paid free food...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                post                 date  \\\n",
       "0         Need more camp to house all foreign worker  2020-04-15 15:09:00   \n",
       "1  Im interested in the clusters esp new ones. Wh...  2020-04-29 23:07:00   \n",
       "2               did the virus make his kkj buay kia?  2020-04-23 21:22:00   \n",
       "3  I’m not saying there isn’t room for improvemen...  2020-04-08 11:23:23   \n",
       "4  abnn good life no need work get paid and free ...  2020-04-05 13:04:00   \n",
       "\n",
       "         source                                         post_clean  \n",
       "0  hardwarezone                                    need camp house  \n",
       "1  hardwarezone            im interested clusters esp new ones see  \n",
       "2  hardwarezone                                  make kkj buay kia  \n",
       "3        reddit  not saying room improvement point choice nsfs ...  \n",
       "4  hardwarezone  abnn good life no need work get paid free food...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import unlabelled data \n",
    "test = pd.read_csv('./unlabelled_posts/test_posts.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing test data \n",
    "\n",
    "test.isnull().sum()\n",
    "test['post_clean'].fillna('nopost', inplace=True)\n",
    "\n",
    "test_posts = test['post_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    1855\n",
       "0.0     167\n",
       "2.0      33\n",
       "Name: preds_nb, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict test with nb model without smote \n",
    "test_pred_nb = opt_gscv_nb.predict(test_posts)\n",
    "test['preds_nb'] = test_pred_nb\n",
    "test['preds_nb'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    1946\n",
       "0.0      99\n",
       "2.0      10\n",
       "Name: preds_lr, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict test with lr model without smote \n",
    "test_pred_lr = opt_gscv_lr.predict(test_posts)\n",
    "test['preds_lr'] = test_pred_lr\n",
    "test['preds_lr'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit count vectorizer with optimised params \n",
    "# cvec = CountVectorizer(max_df=0.2, max_features=100, min_df=1)\n",
    "cvec_test = cvec.transform(test_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    1173\n",
       "0.0     603\n",
       "2.0     279\n",
       "Name: preds_nb_smote, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict test with nb model with smote \n",
    "test_pred_nb_smote = nb.predict(cvec_test)\n",
    "test['preds_nb_smote'] = test_pred_nb_smote\n",
    "test['preds_nb_smote'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('./labelled_posts/test_nb_lr_labelled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
